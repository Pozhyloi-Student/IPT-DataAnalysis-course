{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a66a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 04:07:24.018134: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 04:07:24.018169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 04:07:24.019371: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 04:07:24.025558: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-22 04:07:30.840636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hermit/anaconda3/envs/my_env/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7531478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m[1] generated_text:\n",
      "\u001b[0;30m'Необхідно створити презентацію, яка коротко ілюструє структуру наукової публікації. Під час презентації необхідно використовувати інформаційні технології, що дозволяють візуально змінювати інформац'\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model='ai-forever/mGPT')\n",
    "\n",
    "generated_texts = generator(\n",
    "    \"Необхідно створити презентацію, яка коротко ілюструє структуру наукової публікації.\",\n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "# Iterate through the generated sequences, replace newline characters, and print\n",
    "for i, generated_text in enumerate(generated_texts):\n",
    "    formatted_text = generated_text['generated_text'].replace(\"\\n\", \" \")\n",
    "    print(f\"\\033[1;34m[{i + 1}] generated_text:\\n\\033[0;30m'{formatted_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df5947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/hermit/anaconda3/envs/my_env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Your max_length is set to 250, but your input_length is only 230. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=115)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized Text (Ukrainian): Українська мережа «АТБ» запускає робот-помічників Delivery Cobot, який може допомогти покупцям інформувати про свої товари, а також подавати їх на онлайн-магазин.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"spursyy/mT5_multilingual_XLSum_rust\")\n",
    "\n",
    "text_to_summarize = \"\"\"\n",
    "Роботи-помічники Delivery Cobot поки що проходять тестування, тож їх можна зустріти наразі лише в декількох магазинах мережі «АТБ» у Дніпрі та Києві.\n",
    "\n",
    "Такий робот-помічник, на відміну від промостійок, не займає багато місця, не заважає покупцям із візками вільно пересуватися торговельними залами. Він мобільний і безперешкодно курсує магазином. \n",
    "\n",
    "Delivery Cobot оснащений головним екраном (розміром трохи більшим аніж звичайний планшет) і кількома поличками. Він може не просто допомагати покупцям, наочно інформуючи про певні товари, ціни чи акційні пропозиції, а ще й фактично подавати ці товари.\n",
    "\n",
    "Цей проєкт свого часу буде масштабовано на всі дискаунтери мережі, яких станом на сьогодні в Україні працює понад 1200.\n",
    "\"\"\"\n",
    "summarized_text = summarizer(text_to_summarize, max_length=250, min_length=50)\n",
    "print(\"Summarized Text (Ukrainian):\", summarized_text[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb1af99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відповідь: {'score': 0.7706676125526428, 'start': 652, 'end': 662, 'answer': ' 15 балів.'}\n"
     ]
    }
   ],
   "source": [
    "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
    "\n",
    "question = \"Чому дорівнює максимальний бал за другу частину контрольної роботи?\"\n",
    "context = \"\"\"\n",
    "Шановні студенти! \n",
    "\n",
    "22 грудня будемо писати контрольну роботу на третій парі,  початок 12-20. \n",
    "Контрольна робота складається з двох частин.   Максимальний бал за першу частину - 10 балів. Перша частина контрольної -- це тести, питання з варіантами відповідей по темах лекцій  9-15,  на розуміння матеріалу.  Прошу вас не запізнюватись, оскільки час на відповіді буде обмежений і нараховуватимуться штрафні бали за невчасну здачу (за кожну хвилину запізнення -0,25 балів). \n",
    "\n",
    "Друга частина роботи -- 1 задача ( розв'язання крайової задачі, розв'язання методом сіток еліптичної, параболічної, гіперболічної задачі). \n",
    "\n",
    "Максимальний бал  за другу частину - 15 балів.\n",
    "\"\"\"\n",
    "\n",
    "answer = qa_model(question = question, context = context)\n",
    "print(\"Відповідь:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e95301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "плани\n",
      "програми\n",
      "план\n",
      "графік\n",
      "розробки\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='xlm-roberta-base', top_k=5)\n",
    "\n",
    "whos = unmasker(\"Лекційні матеріали та <mask> практичних занять можна знайти тут\")\n",
    "for who in whos:\n",
    "    print(who['token_str'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
